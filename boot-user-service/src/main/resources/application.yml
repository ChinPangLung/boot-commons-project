server:
  port: 8082
dubbo:
  application:
    name: boot-user-service
    qosEnable: false
    qosPort: 33333
    qosAcceptForeignIp: false
  registry:
    address: zookeeper://182.254.183.22:2181
    # onitor:
    #    protocol: registry
  protocol:
    name: dubbo
    #    dubbo的配置信息加载顺序是 -D > application.yml > dubbo.properties 默认端口20880
    port: 20881
    #启动时检查 如果提供者服务不存在 check=true时  consumer启动时会报错 check=False时 consumer启动时不报错
  consumer: #这里的配置是对全局有效
    check: false
    #    接口调用响应时间 默认是1000毫秒
    timeout: 1000
    #    接口响应超时 后重试次数 不包含第一次调用 注意：如果是幂等的话可以设置重试次数 如果非幂等的话 不能设置重试次数
    retries: 2 #不建议设置为全局变量

spring:
  jackson: # jackson时间格式化
    date-format: yyyy-MM-dd HH:mm:ss
    time-zone: GMT+8
  data:
    elasticsearch:
      cluster-name: my-application
      cluster-nodes: 127.0.0.1:9300
      repositories:
        enabled: true #开启本地存储
  redis:
    databases: 0 #reids 数据库索引
    host: 182.254.183.22
    port: 6379
    password: redis123 # Redis服务器连接密码（默认为空）
    pool:
      max-active: 200 # 连接池最大连接数（使用负值表示没有限制）
      max-wait: 1 # 连接池最大阻塞等待时间（使用负值表示没有限制）
      max-idle: 10 # 连接池中的最大空闲连接
      min-idle: 0 # 连接池中的最小空闲连接
    time: 1000 # 连接超时时间（毫秒）
  datasource: #数据库配置
    password: mysql123
    type: com.alibaba.druid.pool.DruidDataSource
    url: jdbc:mysql://182.254.183.22:3306/testdb?useUnicode=true$characterEncoding=utf-8
    username: root
    driver-class-name: com.mysql.jdbc.Driver
    druid:
      initial-size: 5
      max-active: 20
      max-pool-prepared-statement-per-connection-size: 20
      max-wait: 60000
      min-evictable-idle-time-millis: 30000
      min-idle: 5
      pool-prepared-statements: true
      test-on-borrow: false
      test-on-return: false
      test-while-idle: true
      time-between-eviction-runs-millis: 60000
      validation-query: SELECT 1 FROM DUAL
#============== kafka ===================  # 指定kafka 代理地址，可以多个
  kafka:
    bootstrap-servers: 182.254.183.22:9092
    producer: #=============== producer  =======================#
      retries: 0
      batch-size: 16384 # 每次批量发送消息的数量
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 指定消息key和消息体的编解码方式
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer: #=============== consumer  =======================# 指定默认消费者group id
      group-id: user-log-group
      auto-offset-reset: earliest
      enable-auto-commit: true
      auto-commit-interval: 100
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer # 指定消息key和消息体的编解码方式
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
mybatis-plus:
  configuration:
    cache-enabled: true
    lazy-loading-enabled: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #打印sql语句,调试用
    map-underscore-to-camel-case: true
  global-config:
    db-column-underline: false
    id-type: 0 #0:数据库ID自增   1:用户输入id  2:全局唯一id(IdWorker)  3:全局唯一ID(uuid)
    refresh-mapper: true
  mapper-locations: classpath:/mapper/*Mapper.xml
  typeAliasesPackage: com.lung.application.model.entity
